# -*- coding: utf-8 -*-
"""Task6.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TRfAwBsg_k1WVm2svMWjkxiMyfV9ROHC
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

dataset = pd.read_csv('CC GENERAL.csv')

dataset.shape

dataset.head()

dataset.drop(columns = 'CUST_ID', inplace = True)

dataset.describe()

dataset.isnull().sum()

dataset = dataset.fillna(dataset.mean())

cols = 4
num_features = dataset.shape[1]
rows = int(np.ceil(num_features / cols))

# Create subplots matrix
plt.figure(figsize=(20, rows * 3))

for i, column in enumerate(dataset.columns):
    plt.subplot(rows, cols, i + 1)
    sns.boxplot(y=dataset[column], color="skyblue")
    plt.title(column, fontsize=10)
    plt.tight_layout()

plt.suptitle("Boxplots of All Features (Outlier Detection)", fontsize=16, y=1.02)
plt.show()

Q1 = dataset.quantile(0.08)
Q3 = dataset.quantile(0.95)
IQR = Q3 - Q1

lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR
dataset_cleaned = dataset[~((dataset < lower_bound) | (dataset > upper_bound)).any(axis=1)]

print("Original dataset shape:", dataset.shape)
print("After outlier removal:", dataset_cleaned.shape)

"""here we have around 4.25% of loss"""

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X = scaler.fit_transform(dataset_cleaned)

from sklearn.cluster import KMeans
sse = []
for k in range(1,10):
    km = KMeans(n_clusters=k, random_state=42)
    km.fit(X)
    sse.append(km.inertia_)
plt.plot(range(1,10), sse, marker='o')
plt.title('Elbow Method')
plt.xlabel('Number of clusters')
plt.ylabel('SSE')
plt.show()

"""we will take k=6

```
# This is formatted as code
```


"""

from sklearn.cluster import KMeans
k = 6
km = KMeans(n_clusters=k, random_state=42, n_init=10)
labels = km.fit_predict(X)
# Create a copy to avoid SettingWithCopyWarning
dataset_cleaned_copy = dataset_cleaned.copy()
dataset_cleaned_copy['cluster_kmeans'] = labels

from sklearn.decomposition import PCA
pca = PCA(n_components=3)
coords = pca.fit_transform(X)
plt.figure(figsize=(8,6))
sns.scatterplot(x=coords[:,0], y=coords[:,1], hue=labels, palette='tab10')
plt.title("K-means clusters (k={})".format(k))
plt.show()

X.groupby('cluster_kmeans').mean()

from scipy.cluster.hierarchy import linkage, dendrogram

sample_idx = np.random.choice(range(len(X)), size=500, replace=False)
X_sub = X[sample_idx]

link_mat = linkage(X_sub, method='ward')
plt.figure(figsize=(10,6))
dendrogram(link_mat, truncate_mode='level', p=5)
plt.title("Dendrogram for Hierarchical Clustering")
plt.xlabel("Data Points")
plt.ylabel("Distance")
plt.show()

from sklearn.cluster import AgglomerativeClustering
n_clusters = 5
ag = AgglomerativeClustering(n_clusters=n_clusters, linkage='ward')
labels_h = ag.fit_predict(X)

dataset_cleaned_copy['cluster_hier'] = labels_h